# Code
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0b1a9c2-4da6-43ce-b8fc-9c12d08477aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting spatial filter on 121 files…\n",
      " ▶ Reading hais_2024-01-01.csv\n",
      "   Done hais_2024-01-01.csv\n",
      " ▶ Reading hais_2024-01-02.csv\n",
      "   Done hais_2024-01-02.csv\n",
      " ▶ Reading hais_2024-01-03.csv\n",
      "   Done hais_2024-01-03.csv\n",
      " ▶ Reading hais_2024-01-04.csv\n",
      "   Done hais_2024-01-04.csv\n",
      " ▶ Reading hais_2024-01-05.csv\n",
      "   Done hais_2024-01-05.csv\n",
      " ▶ Reading hais_2024-01-06.csv\n",
      "   Done hais_2024-01-06.csv\n",
      " ▶ Reading hais_2024-01-07.csv\n",
      "   Done hais_2024-01-07.csv\n",
      " ▶ Reading hais_2024-01-08.csv\n",
      "   Done hais_2024-01-08.csv\n",
      " ▶ Reading hais_2024-01-09.csv\n",
      "   Done hais_2024-01-09.csv\n",
      " ▶ Reading hais_2024-01-10.csv\n",
      "   Done hais_2024-01-10.csv\n",
      " ▶ Reading hais_2024-01-11.csv\n",
      "   Done hais_2024-01-11.csv\n",
      " ▶ Reading hais_2024-01-12.csv\n",
      "   Done hais_2024-01-12.csv\n",
      " ▶ Reading hais_2024-01-13.csv\n",
      "   Done hais_2024-01-13.csv\n",
      " ▶ Reading hais_2024-01-14.csv\n",
      "   Done hais_2024-01-14.csv\n",
      " ▶ Reading hais_2024-01-15.csv\n",
      "   Done hais_2024-01-15.csv\n",
      " ▶ Reading hais_2024-01-16.csv\n",
      "   Done hais_2024-01-16.csv\n",
      " ▶ Reading hais_2024-01-17.csv\n",
      "   Done hais_2024-01-17.csv\n",
      " ▶ Reading hais_2024-01-18.csv\n",
      "   Done hais_2024-01-18.csv\n",
      " ▶ Reading hais_2024-01-19.csv\n",
      "   Done hais_2024-01-19.csv\n",
      " ▶ Reading hais_2024-01-20.csv\n",
      "   Done hais_2024-01-20.csv\n",
      " ▶ Reading hais_2024-01-21.csv\n",
      "   Done hais_2024-01-21.csv\n",
      " ▶ Reading hais_2024-01-22.csv\n",
      "   Done hais_2024-01-22.csv\n",
      " ▶ Reading hais_2024-01-23.csv\n",
      "   Done hais_2024-01-23.csv\n",
      " ▶ Reading hais_2024-01-24.csv\n",
      "   Done hais_2024-01-24.csv\n",
      " ▶ Reading hais_2024-01-25.csv\n",
      "   Done hais_2024-01-25.csv\n",
      " ▶ Reading hais_2024-01-26.csv\n",
      "   Done hais_2024-01-26.csv\n",
      " ▶ Reading hais_2024-01-27.csv\n",
      "   Done hais_2024-01-27.csv\n",
      " ▶ Reading hais_2024-01-28.csv\n",
      "   Done hais_2024-01-28.csv\n",
      " ▶ Reading hais_2024-01-29.csv\n",
      "   Done hais_2024-01-29.csv\n",
      " ▶ Reading hais_2024-01-30.csv\n",
      "   Done hais_2024-01-30.csv\n",
      " ▶ Reading hais_2024-01-31.csv\n",
      "   Done hais_2024-01-31.csv\n",
      " ▶ Reading hais_2024-02-01.csv\n",
      "   Done hais_2024-02-01.csv\n",
      " ▶ Reading hais_2024-02-02.csv\n",
      "   Done hais_2024-02-02.csv\n",
      " ▶ Reading hais_2024-02-03.csv\n",
      "   Done hais_2024-02-03.csv\n",
      " ▶ Reading hais_2024-02-04.csv\n",
      "   Done hais_2024-02-04.csv\n",
      " ▶ Reading hais_2024-02-05.csv\n",
      "   Done hais_2024-02-05.csv\n",
      " ▶ Reading hais_2024-02-06.csv\n",
      "   Done hais_2024-02-06.csv\n",
      " ▶ Reading hais_2024-02-07.csv\n",
      "   Done hais_2024-02-07.csv\n",
      " ▶ Reading hais_2024-02-08.csv\n",
      "   Done hais_2024-02-08.csv\n",
      " ▶ Reading hais_2024-02-09.csv\n",
      "   Done hais_2024-02-09.csv\n",
      " ▶ Reading hais_2024-02-10.csv\n",
      "   Done hais_2024-02-10.csv\n",
      " ▶ Reading hais_2024-02-11.csv\n",
      "   Done hais_2024-02-11.csv\n",
      " ▶ Reading hais_2024-02-12.csv\n",
      "   Done hais_2024-02-12.csv\n",
      " ▶ Reading hais_2024-02-13.csv\n",
      "   Done hais_2024-02-13.csv\n",
      " ▶ Reading hais_2024-02-14.csv\n",
      "   Done hais_2024-02-14.csv\n",
      " ▶ Reading hais_2024-02-15.csv\n",
      "   Done hais_2024-02-15.csv\n",
      " ▶ Reading hais_2024-02-16.csv\n",
      "   Done hais_2024-02-16.csv\n",
      " ▶ Reading hais_2024-02-17.csv\n",
      "   Done hais_2024-02-17.csv\n",
      " ▶ Reading hais_2024-02-18.csv\n",
      "   Done hais_2024-02-18.csv\n",
      " ▶ Reading hais_2024-02-19.csv\n",
      "   Done hais_2024-02-19.csv\n",
      " ▶ Reading hais_2024-02-20.csv\n",
      "   Done hais_2024-02-20.csv\n",
      " ▶ Reading hais_2024-02-21.csv\n",
      "   Done hais_2024-02-21.csv\n",
      " ▶ Reading hais_2024-02-22.csv\n",
      "   Done hais_2024-02-22.csv\n",
      " ▶ Reading hais_2024-02-23.csv\n",
      "   Done hais_2024-02-23.csv\n",
      " ▶ Reading hais_2024-02-24.csv\n",
      "   Done hais_2024-02-24.csv\n",
      " ▶ Reading hais_2024-02-25.csv\n",
      "   Done hais_2024-02-25.csv\n",
      " ▶ Reading hais_2024-02-26.csv\n",
      "   Done hais_2024-02-26.csv\n",
      " ▶ Reading hais_2024-02-27.csv\n",
      "   Done hais_2024-02-27.csv\n",
      " ▶ Reading hais_2024-02-28.csv\n",
      "   Done hais_2024-02-28.csv\n",
      " ▶ Reading hais_2024-02-29.csv\n",
      "   Done hais_2024-02-29.csv\n",
      " ▶ Reading hais_2024-03-01.csv\n",
      "   Done hais_2024-03-01.csv\n",
      " ▶ Reading hais_2024-03-02.csv\n",
      "   Done hais_2024-03-02.csv\n",
      " ▶ Reading hais_2024-03-03.csv\n",
      "   Done hais_2024-03-03.csv\n",
      " ▶ Reading hais_2024-03-04.csv\n",
      "   Done hais_2024-03-04.csv\n",
      " ▶ Reading hais_2024-03-05.csv\n",
      "   Done hais_2024-03-05.csv\n",
      " ▶ Reading hais_2024-03-06.csv\n",
      "   Done hais_2024-03-06.csv\n",
      " ▶ Reading hais_2024-03-07.csv\n",
      "   Done hais_2024-03-07.csv\n",
      " ▶ Reading hais_2024-03-08.csv\n",
      "   Done hais_2024-03-08.csv\n",
      " ▶ Reading hais_2024-03-09.csv\n",
      "   Done hais_2024-03-09.csv\n",
      " ▶ Reading hais_2024-03-10.csv\n",
      "   Done hais_2024-03-10.csv\n",
      " ▶ Reading hais_2024-03-11.csv\n",
      "   Done hais_2024-03-11.csv\n",
      " ▶ Reading hais_2024-03-12.csv\n",
      "   Done hais_2024-03-12.csv\n",
      " ▶ Reading hais_2024-03-13.csv\n",
      "   Done hais_2024-03-13.csv\n",
      " ▶ Reading hais_2024-03-14.csv\n",
      "   Done hais_2024-03-14.csv\n",
      " ▶ Reading hais_2024-03-15.csv\n",
      "   Done hais_2024-03-15.csv\n",
      " ▶ Reading hais_2024-03-16.csv\n",
      "   Done hais_2024-03-16.csv\n",
      " ▶ Reading hais_2024-03-17.csv\n",
      "   Done hais_2024-03-17.csv\n",
      " ▶ Reading hais_2024-03-18.csv\n",
      "   Done hais_2024-03-18.csv\n",
      " ▶ Reading hais_2024-03-19.csv\n",
      "   Done hais_2024-03-19.csv\n",
      " ▶ Reading hais_2024-03-20.csv\n",
      "   Done hais_2024-03-20.csv\n",
      " ▶ Reading hais_2024-03-21.csv\n",
      "   Done hais_2024-03-21.csv\n",
      " ▶ Reading hais_2024-03-22.csv\n",
      "   Done hais_2024-03-22.csv\n",
      " ▶ Reading hais_2024-03-23.csv\n",
      "   Done hais_2024-03-23.csv\n",
      " ▶ Reading hais_2024-03-24.csv\n",
      "   Done hais_2024-03-24.csv\n",
      " ▶ Reading hais_2024-03-25.csv\n",
      "   Done hais_2024-03-25.csv\n",
      " ▶ Reading hais_2024-03-26.csv\n",
      "   Done hais_2024-03-26.csv\n",
      " ▶ Reading hais_2024-03-27.csv\n",
      "   Done hais_2024-03-27.csv\n",
      " ▶ Reading hais_2024-03-28.csv\n",
      "   Done hais_2024-03-28.csv\n",
      " ▶ Reading hais_2024-03-29.csv\n",
      "   Done hais_2024-03-29.csv\n",
      " ▶ Reading hais_2024-03-30.csv\n",
      "   Done hais_2024-03-30.csv\n",
      " ▶ Reading hais_2024-03-31.csv\n",
      "   Done hais_2024-03-31.csv\n",
      " ▶ Reading hais_2024-04-01.csv\n",
      "   Done hais_2024-04-01.csv\n",
      " ▶ Reading hais_2024-04-02.csv\n",
      "   Done hais_2024-04-02.csv\n",
      " ▶ Reading hais_2024-04-03.csv\n",
      "   Done hais_2024-04-03.csv\n",
      " ▶ Reading hais_2024-04-04.csv\n",
      "   Done hais_2024-04-04.csv\n",
      " ▶ Reading hais_2024-04-05.csv\n",
      "   Done hais_2024-04-05.csv\n",
      " ▶ Reading hais_2024-04-06.csv\n",
      "   Done hais_2024-04-06.csv\n",
      " ▶ Reading hais_2024-04-07.csv\n",
      "   Done hais_2024-04-07.csv\n",
      " ▶ Reading hais_2024-04-08.csv\n",
      "   Done hais_2024-04-08.csv\n",
      " ▶ Reading hais_2024-04-09.csv\n",
      "   Done hais_2024-04-09.csv\n",
      " ▶ Reading hais_2024-04-10.csv\n",
      "   Done hais_2024-04-10.csv\n",
      " ▶ Reading hais_2024-04-11.csv\n",
      "   Done hais_2024-04-11.csv\n",
      " ▶ Reading hais_2024-04-12.csv\n",
      "   Done hais_2024-04-12.csv\n",
      " ▶ Reading hais_2024-04-13.csv\n",
      "   Done hais_2024-04-13.csv\n",
      " ▶ Reading hais_2024-04-14.csv\n",
      "   Done hais_2024-04-14.csv\n",
      " ▶ Reading hais_2024-04-15.csv\n",
      "   Done hais_2024-04-15.csv\n",
      " ▶ Reading hais_2024-04-16.csv\n",
      "   Done hais_2024-04-16.csv\n",
      " ▶ Reading hais_2024-04-17.csv\n",
      "   Done hais_2024-04-17.csv\n",
      " ▶ Reading hais_2024-04-18.csv\n",
      "   Done hais_2024-04-18.csv\n",
      " ▶ Reading hais_2024-04-19.csv\n",
      "   Done hais_2024-04-19.csv\n",
      " ▶ Reading hais_2024-04-20.csv\n",
      "   Done hais_2024-04-20.csv\n",
      " ▶ Reading hais_2024-04-21.csv\n",
      "   Done hais_2024-04-21.csv\n",
      " ▶ Reading hais_2024-04-22.csv\n",
      "   Done hais_2024-04-22.csv\n",
      " ▶ Reading hais_2024-04-23.csv\n",
      "   Done hais_2024-04-23.csv\n",
      " ▶ Reading hais_2024-04-24.csv\n",
      "   Done hais_2024-04-24.csv\n",
      " ▶ Reading hais_2024-04-25.csv\n",
      "   Done hais_2024-04-25.csv\n",
      " ▶ Reading hais_2024-04-26.csv\n",
      "   Done hais_2024-04-26.csv\n",
      " ▶ Reading hais_2024-04-27.csv\n",
      "   Done hais_2024-04-27.csv\n",
      " ▶ Reading hais_2024-04-28.csv\n",
      "   Done hais_2024-04-28.csv\n",
      " ▶ Reading hais_2024-04-29.csv\n",
      "   Done hais_2024-04-29.csv\n",
      " ▶ Reading hais_2024-04-30.csv\n",
      "   Done hais_2024-04-30.csv\n",
      "\n",
      "Rows retained per port:\n",
      " • Bergen: 3,086,168 rows → norway_ports_filtered\\Bergen\\all_data.csv\n",
      " • Stavanger: 1,199,117 rows → norway_ports_filtered\\Stavanger\\all_data.csv\n",
      " • Kristiansand: 331,660 rows → norway_ports_filtered\\Kristiansand\\all_data.csv\n",
      " • Haugesund: 1,303,646 rows → norway_ports_filtered\\Haugesund\\all_data.csv\n",
      " • Larvik: 114,568 rows → norway_ports_filtered\\Larvik\\all_data.csv\n",
      " • Moss: 380,127 rows → norway_ports_filtered\\Moss\\all_data.csv\n",
      " • Drammen: 285,673 rows → norway_ports_filtered\\Drammen\\all_data.csv\n",
      " • Oslo: 1,108,374 rows → norway_ports_filtered\\Oslo\\all_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from shapely.geometry import Point, Polygon\n",
    "from pathlib import Path\n",
    "\n",
    "# ── CONFIGURATION ──\n",
    "CHUNK_SIZE = 500_000\n",
    "IN_DIR     = Path('.')                       # current working directory\n",
    "OUT_BASE   = IN_DIR / \"norway_ports_filtered\"\n",
    "OUT_BASE.mkdir(exist_ok=True)\n",
    "\n",
    "# ── DEFINE YOUR NORWAY PORT POLYGONS (lon, lat) ──\n",
    "port_polygons = {\n",
    "    \"Bergen\": Polygon([\n",
    "        (5.3119966, 60.4048807),\n",
    "        (5.2689096, 60.3941969),\n",
    "        (5.3233262, 60.3710367),\n",
    "        (5.3526803, 60.3832551),\n",
    "        (5.3119966, 60.4048807),\n",
    "    ]),\n",
    "    \"Stavanger\": Polygon([\n",
    "        (5.5596949, 58.9367236),\n",
    "        (5.5461337, 58.9152819),\n",
    "        (5.5955721, 58.9039355),\n",
    "        (5.6122233, 58.9324718),\n",
    "        (5.5596949, 58.9367236),\n",
    "    ]),\n",
    "    \"Kristiansand\": Polygon([\n",
    "        (8.0021276, 58.157283),\n",
    "        (7.9581823, 58.1337279),\n",
    "        (8.0220403, 58.1192246),\n",
    "        (8.0388631, 58.1449638),\n",
    "        (8.0021276, 58.157283),\n",
    "    ]),\n",
    "    \"Haugesund\": Polygon([\n",
    "        (5.2809529, 59.351359),\n",
    "        (5.2675634, 59.3426946),\n",
    "        (5.2979474, 59.3231697),\n",
    "        (5.3307347, 59.3342031),\n",
    "        (5.32095,   59.3522341),\n",
    "        (5.2809529, 59.351359),\n",
    "    ]),\n",
    "    \"Larvik\": Polygon([\n",
    "        (10.0060228, 59.0470095),\n",
    "        (10.0200991, 59.0198933),\n",
    "        (10.0786356, 59.03129),\n",
    "        (10.0568346, 59.0541603),\n",
    "        (10.0146059, 59.0497464),\n",
    "        (10.0060228, 59.0470095),\n",
    "    ]),\n",
    "    \"Moss\": Polygon([\n",
    "        (10.6414806, 59.4396391),\n",
    "        (10.6102382, 59.4125713),\n",
    "        (10.6557285, 59.4072425),\n",
    "        (10.673238,  59.4375443),\n",
    "        (10.6414806, 59.4396391),\n",
    "    ]),\n",
    "    \"Drammen\": Polygon([\n",
    "        (10.2470522, 59.7538991),\n",
    "        (10.1914339, 59.7347841),\n",
    "        (10.2879076, 59.7134939),\n",
    "        (10.3028421, 59.7476728),\n",
    "        (10.2470522, 59.7538991),\n",
    "    ]),\n",
    "    \"Oslo\": Polygon([\n",
    "        (10.7220254, 59.9127971),\n",
    "        (10.6775651, 59.9016079),\n",
    "        (10.7091508, 59.8693961),\n",
    "        (10.7781586, 59.8841278),\n",
    "        (10.7587609, 59.9135716),\n",
    "        (10.7220254, 59.9127971),\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# ── PRECOMPUTE BOUNDING BOXES FOR FAST PREFILTER ──\n",
    "port_bounds = {name: poly.bounds for name, poly in port_polygons.items()}\n",
    "\n",
    "# ── SET UP OUTPUT WRITERS & SUMMARY COUNTERS ──\n",
    "writers = {port: {\"path\": OUT_BASE/port/\"all_data.csv\", \"first\": True}\n",
    "           for port in port_polygons}\n",
    "summary = {port: 0 for port in port_polygons}\n",
    "\n",
    "for port in writers:\n",
    "    (OUT_BASE/port).mkdir(exist_ok=True)\n",
    "\n",
    "# ── PROCESS EACH CSV IN CHUNKS ──\n",
    "csv_files = sorted(Path('.').glob(\"*.csv\"))\n",
    "print(f\"Starting spatial filter on {len(csv_files)} files…\")\n",
    "\n",
    "for src in csv_files:\n",
    "    print(f\" ▶ Reading {src.name}\")\n",
    "    for chunk in pd.read_csv(\n",
    "        src,\n",
    "        chunksize=CHUNK_SIZE,\n",
    "        parse_dates=['date_time_utc'],\n",
    "        low_memory=False\n",
    "    ):\n",
    "        # drop rows missing coords\n",
    "        chunk = chunk.dropna(subset=[\"latitude\", \"longitude\"])\n",
    "        \n",
    "        # for each port: bounding-box then polygon test\n",
    "        for port, poly in port_polygons.items():\n",
    "            minx, miny, maxx, maxy = port_bounds[port]\n",
    "            bb_mask = (\n",
    "                (chunk[\"longitude\"] >= minx) &\n",
    "                (chunk[\"longitude\"] <= maxx) &\n",
    "                (chunk[\"latitude\"]  >= miny) &\n",
    "                (chunk[\"latitude\"]  <= maxy)\n",
    "            )\n",
    "            candidate = chunk[bb_mask]\n",
    "            if candidate.empty:\n",
    "                continue\n",
    "            \n",
    "            # precise geometry containment\n",
    "            mask = candidate.apply(\n",
    "                lambda r: poly.contains(Point(r[\"longitude\"], r[\"latitude\"])),\n",
    "                axis=1\n",
    "            )\n",
    "            filtered = candidate[mask]\n",
    "            if filtered.empty:\n",
    "                continue\n",
    "            \n",
    "            # write out ALL columns for rows inside this port\n",
    "            w = writers[port]\n",
    "            if w[\"first\"]:\n",
    "                filtered.to_csv(w[\"path\"], index=False, mode='w')\n",
    "                w[\"first\"] = False\n",
    "            else:\n",
    "                filtered.to_csv(w[\"path\"], index=False, header=False, mode='a')\n",
    "            \n",
    "            summary[port] += len(filtered)\n",
    "    \n",
    "    print(f\"   Done {src.name}\")\n",
    "\n",
    "# ── FINAL SUMMARY ──\n",
    "print(\"\\nRows retained per port:\")\n",
    "for port, cnt in summary.items():\n",
    "    print(f\" • {port}: {cnt:,} rows → {writers[port]['path']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f105185f-3ee3-4396-b9d7-71304f9cac12",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
