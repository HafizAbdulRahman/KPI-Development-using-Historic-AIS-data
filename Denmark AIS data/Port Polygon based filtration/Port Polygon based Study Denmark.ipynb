{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d9a3d0a-716f-4a0d-aac3-351428f3f811",
   "metadata": {},
   "source": [
    "## Here i have "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da78aafb-6fdb-42e6-bacd-05c7fd0beebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting spatial filter on 110 files…\n",
      " ▶ Reading aisdk-2025-01-01.csv\n",
      "   Done aisdk-2025-01-01.csv\n",
      " ▶ Reading aisdk-2025-01-02.csv\n",
      "   Done aisdk-2025-01-02.csv\n",
      " ▶ Reading aisdk-2025-01-03.csv\n",
      "   Done aisdk-2025-01-03.csv\n",
      " ▶ Reading aisdk-2025-01-04.csv\n",
      "   Done aisdk-2025-01-04.csv\n",
      " ▶ Reading aisdk-2025-01-05.csv\n",
      "   Done aisdk-2025-01-05.csv\n",
      " ▶ Reading aisdk-2025-01-06.csv\n",
      "   Done aisdk-2025-01-06.csv\n",
      " ▶ Reading aisdk-2025-01-07.csv\n",
      "   Done aisdk-2025-01-07.csv\n",
      " ▶ Reading aisdk-2025-01-08.csv\n",
      "   Done aisdk-2025-01-08.csv\n",
      " ▶ Reading aisdk-2025-01-09.csv\n",
      "   Done aisdk-2025-01-09.csv\n",
      " ▶ Reading aisdk-2025-01-10.csv\n",
      "   Done aisdk-2025-01-10.csv\n",
      " ▶ Reading aisdk-2025-01-11.csv\n",
      "   Done aisdk-2025-01-11.csv\n",
      " ▶ Reading aisdk-2025-01-12.csv\n",
      "   Done aisdk-2025-01-12.csv\n",
      " ▶ Reading aisdk-2025-01-13.csv\n",
      "   Done aisdk-2025-01-13.csv\n",
      " ▶ Reading aisdk-2025-01-14.csv\n",
      "   Done aisdk-2025-01-14.csv\n",
      " ▶ Reading aisdk-2025-01-15.csv\n",
      "   Done aisdk-2025-01-15.csv\n",
      " ▶ Reading aisdk-2025-01-16.csv\n",
      "   Done aisdk-2025-01-16.csv\n",
      " ▶ Reading aisdk-2025-01-17.csv\n",
      "   Done aisdk-2025-01-17.csv\n",
      " ▶ Reading aisdk-2025-01-18.csv\n",
      "   Done aisdk-2025-01-18.csv\n",
      " ▶ Reading aisdk-2025-01-19.csv\n",
      "   Done aisdk-2025-01-19.csv\n",
      " ▶ Reading aisdk-2025-01-20.csv\n",
      "   Done aisdk-2025-01-20.csv\n",
      " ▶ Reading aisdk-2025-01-21.csv\n",
      "   Done aisdk-2025-01-21.csv\n",
      " ▶ Reading aisdk-2025-01-22.csv\n",
      "   Done aisdk-2025-01-22.csv\n",
      " ▶ Reading aisdk-2025-01-23.csv\n",
      "   Done aisdk-2025-01-23.csv\n",
      " ▶ Reading aisdk-2025-01-24.csv\n",
      "   Done aisdk-2025-01-24.csv\n",
      " ▶ Reading aisdk-2025-01-25.csv\n",
      "   Done aisdk-2025-01-25.csv\n",
      " ▶ Reading aisdk-2025-01-26.csv\n",
      "   Done aisdk-2025-01-26.csv\n",
      " ▶ Reading aisdk-2025-01-27.csv\n",
      "   Done aisdk-2025-01-27.csv\n",
      " ▶ Reading aisdk-2025-01-28.csv\n",
      "   Done aisdk-2025-01-28.csv\n",
      " ▶ Reading aisdk-2025-01-29.csv\n",
      "   Done aisdk-2025-01-29.csv\n",
      " ▶ Reading aisdk-2025-01-30.csv\n",
      "   Done aisdk-2025-01-30.csv\n",
      " ▶ Reading aisdk-2025-01-31.csv\n",
      "   Done aisdk-2025-01-31.csv\n",
      " ▶ Reading aisdk-2025-02-01.csv\n",
      "   Done aisdk-2025-02-01.csv\n",
      " ▶ Reading aisdk-2025-02-02.csv\n",
      "   Done aisdk-2025-02-02.csv\n",
      " ▶ Reading aisdk-2025-02-03.csv\n",
      "   Done aisdk-2025-02-03.csv\n",
      " ▶ Reading aisdk-2025-02-04.csv\n",
      "   Done aisdk-2025-02-04.csv\n",
      " ▶ Reading aisdk-2025-02-05.csv\n",
      "   Done aisdk-2025-02-05.csv\n",
      " ▶ Reading aisdk-2025-02-06.csv\n",
      "   Done aisdk-2025-02-06.csv\n",
      " ▶ Reading aisdk-2025-02-07.csv\n",
      "   Done aisdk-2025-02-07.csv\n",
      " ▶ Reading aisdk-2025-02-08.csv\n",
      "   Done aisdk-2025-02-08.csv\n",
      " ▶ Reading aisdk-2025-02-09.csv\n",
      "   Done aisdk-2025-02-09.csv\n",
      " ▶ Reading aisdk-2025-02-10.csv\n",
      "   Done aisdk-2025-02-10.csv\n",
      " ▶ Reading aisdk-2025-02-11.csv\n",
      "   Done aisdk-2025-02-11.csv\n",
      " ▶ Reading aisdk-2025-02-12.csv\n",
      "   Done aisdk-2025-02-12.csv\n",
      " ▶ Reading aisdk-2025-02-13.csv\n",
      "   Done aisdk-2025-02-13.csv\n",
      " ▶ Reading aisdk-2025-02-14.csv\n",
      "   Done aisdk-2025-02-14.csv\n",
      " ▶ Reading aisdk-2025-02-15.csv\n",
      "   Done aisdk-2025-02-15.csv\n",
      " ▶ Reading aisdk-2025-02-16.csv\n",
      "   Done aisdk-2025-02-16.csv\n",
      " ▶ Reading aisdk-2025-02-17.csv\n",
      "   Done aisdk-2025-02-17.csv\n",
      " ▶ Reading aisdk-2025-02-18.csv\n",
      "   Done aisdk-2025-02-18.csv\n",
      " ▶ Reading aisdk-2025-02-19.csv\n",
      "   Done aisdk-2025-02-19.csv\n",
      " ▶ Reading aisdk-2025-02-20.csv\n",
      "   Done aisdk-2025-02-20.csv\n",
      " ▶ Reading aisdk-2025-02-21.csv\n",
      "   Done aisdk-2025-02-21.csv\n",
      " ▶ Reading aisdk-2025-02-22.csv\n",
      "   Done aisdk-2025-02-22.csv\n",
      " ▶ Reading aisdk-2025-02-23.csv\n",
      "   Done aisdk-2025-02-23.csv\n",
      " ▶ Reading aisdk-2025-02-24.csv\n",
      "   Done aisdk-2025-02-24.csv\n",
      " ▶ Reading aisdk-2025-02-25.csv\n",
      "   Done aisdk-2025-02-25.csv\n",
      " ▶ Reading aisdk-2025-02-26.csv\n",
      "   Done aisdk-2025-02-26.csv\n",
      " ▶ Reading aisdk-2025-02-27.csv\n",
      "   Done aisdk-2025-02-27.csv\n",
      " ▶ Reading aisdk-2025-02-28.csv\n",
      "   Done aisdk-2025-02-28.csv\n",
      " ▶ Reading aisdk-2025-03-01.csv\n",
      "   Done aisdk-2025-03-01.csv\n",
      " ▶ Reading aisdk-2025-03-02.csv\n",
      "   Done aisdk-2025-03-02.csv\n",
      " ▶ Reading aisdk-2025-03-03.csv\n",
      "   Done aisdk-2025-03-03.csv\n",
      " ▶ Reading aisdk-2025-03-04.csv\n",
      "   Done aisdk-2025-03-04.csv\n",
      " ▶ Reading aisdk-2025-03-05.csv\n",
      "   Done aisdk-2025-03-05.csv\n",
      " ▶ Reading aisdk-2025-03-06.csv\n",
      "   Done aisdk-2025-03-06.csv\n",
      " ▶ Reading aisdk-2025-03-07.csv\n",
      "   Done aisdk-2025-03-07.csv\n",
      " ▶ Reading aisdk-2025-03-08.csv\n",
      "   Done aisdk-2025-03-08.csv\n",
      " ▶ Reading aisdk-2025-03-09.csv\n",
      "   Done aisdk-2025-03-09.csv\n",
      " ▶ Reading aisdk-2025-03-10.csv\n",
      "   Done aisdk-2025-03-10.csv\n",
      " ▶ Reading aisdk-2025-03-11.csv\n",
      "   Done aisdk-2025-03-11.csv\n",
      " ▶ Reading aisdk-2025-03-12.csv\n",
      "   Done aisdk-2025-03-12.csv\n",
      " ▶ Reading aisdk-2025-03-13.csv\n",
      "   Done aisdk-2025-03-13.csv\n",
      " ▶ Reading aisdk-2025-03-14.csv\n",
      "   Done aisdk-2025-03-14.csv\n",
      " ▶ Reading aisdk-2025-03-15.csv\n",
      "   Done aisdk-2025-03-15.csv\n",
      " ▶ Reading aisdk-2025-03-16.csv\n",
      "   Done aisdk-2025-03-16.csv\n",
      " ▶ Reading aisdk-2025-03-17.csv\n",
      "   Done aisdk-2025-03-17.csv\n",
      " ▶ Reading aisdk-2025-03-18.csv\n",
      "   Done aisdk-2025-03-18.csv\n",
      " ▶ Reading aisdk-2025-03-19.csv\n",
      "   Done aisdk-2025-03-19.csv\n",
      " ▶ Reading aisdk-2025-03-20.csv\n",
      "   Done aisdk-2025-03-20.csv\n",
      " ▶ Reading aisdk-2025-03-21.csv\n",
      "   Done aisdk-2025-03-21.csv\n",
      " ▶ Reading aisdk-2025-03-22.csv\n",
      "   Done aisdk-2025-03-22.csv\n",
      " ▶ Reading aisdk-2025-03-23.csv\n",
      "   Done aisdk-2025-03-23.csv\n",
      " ▶ Reading aisdk-2025-03-24.csv\n",
      "   Done aisdk-2025-03-24.csv\n",
      " ▶ Reading aisdk-2025-03-25.csv\n",
      "   Done aisdk-2025-03-25.csv\n",
      " ▶ Reading aisdk-2025-03-26.csv\n",
      "   Done aisdk-2025-03-26.csv\n",
      " ▶ Reading aisdk-2025-03-27.csv\n",
      "   Done aisdk-2025-03-27.csv\n",
      " ▶ Reading aisdk-2025-03-28.csv\n",
      "   Done aisdk-2025-03-28.csv\n",
      " ▶ Reading aisdk-2025-03-29.csv\n",
      "   Done aisdk-2025-03-29.csv\n",
      " ▶ Reading aisdk-2025-03-30.csv\n",
      "   Done aisdk-2025-03-30.csv\n",
      " ▶ Reading aisdk-2025-03-31.csv\n",
      "   Done aisdk-2025-03-31.csv\n",
      " ▶ Reading aisdk-2025-04-01.csv\n",
      "   Done aisdk-2025-04-01.csv\n",
      " ▶ Reading aisdk-2025-04-02.csv\n",
      "   Done aisdk-2025-04-02.csv\n",
      " ▶ Reading aisdk-2025-04-03.csv\n",
      "   Done aisdk-2025-04-03.csv\n",
      " ▶ Reading aisdk-2025-04-04.csv\n",
      "   Done aisdk-2025-04-04.csv\n",
      " ▶ Reading aisdk-2025-04-05.csv\n",
      "   Done aisdk-2025-04-05.csv\n",
      " ▶ Reading aisdk-2025-04-06.csv\n",
      "   Done aisdk-2025-04-06.csv\n",
      " ▶ Reading aisdk-2025-04-07.csv\n",
      "   Done aisdk-2025-04-07.csv\n",
      " ▶ Reading aisdk-2025-04-08.csv\n",
      "   Done aisdk-2025-04-08.csv\n",
      " ▶ Reading aisdk-2025-04-09.csv\n",
      "   Done aisdk-2025-04-09.csv\n",
      " ▶ Reading aisdk-2025-04-10.csv\n",
      "   Done aisdk-2025-04-10.csv\n",
      " ▶ Reading aisdk-2025-04-11.csv\n",
      "   Done aisdk-2025-04-11.csv\n",
      " ▶ Reading aisdk-2025-04-12.csv\n",
      "   Done aisdk-2025-04-12.csv\n",
      " ▶ Reading aisdk-2025-04-13.csv\n",
      "   Done aisdk-2025-04-13.csv\n",
      " ▶ Reading aisdk-2025-04-14.csv\n",
      "   Done aisdk-2025-04-14.csv\n",
      " ▶ Reading aisdk-2025-04-15.csv\n",
      "   Done aisdk-2025-04-15.csv\n",
      " ▶ Reading aisdk-2025-04-16.csv\n",
      "   Done aisdk-2025-04-16.csv\n",
      " ▶ Reading aisdk-2025-04-17.csv\n",
      "   Done aisdk-2025-04-17.csv\n",
      " ▶ Reading aisdk-2025-04-18.csv\n",
      "   Done aisdk-2025-04-18.csv\n",
      " ▶ Reading aisdk-2025-04-19.csv\n",
      "   Done aisdk-2025-04-19.csv\n",
      " ▶ Reading aisdk-2025-04-20.csv\n",
      "   Done aisdk-2025-04-20.csv\n",
      "\n",
      "Rows retained per port:\n",
      " • Aarhaus: 1,512,866 rows → D:\\Thesis Work MLS\\Denmark AIS data\\processed_files\\ports_filtered_flat\\Aarhaus.csv\n",
      " • Copenhagen: 538,355 rows → D:\\Thesis Work MLS\\Denmark AIS data\\processed_files\\ports_filtered_flat\\Copenhagen.csv\n",
      " • Esbjerg: 5,764,070 rows → D:\\Thesis Work MLS\\Denmark AIS data\\processed_files\\ports_filtered_flat\\Esbjerg.csv\n",
      " • Fredericia: 788,192 rows → D:\\Thesis Work MLS\\Denmark AIS data\\processed_files\\ports_filtered_flat\\Fredericia.csv\n",
      " • Aalborg: 546,496 rows → D:\\Thesis Work MLS\\Denmark AIS data\\processed_files\\ports_filtered_flat\\Aalborg.csv\n",
      " • Kalundborg: 2,069,880 rows → D:\\Thesis Work MLS\\Denmark AIS data\\processed_files\\ports_filtered_flat\\Kalundborg.csv\n",
      " • Aabenraa: 203,609 rows → D:\\Thesis Work MLS\\Denmark AIS data\\processed_files\\ports_filtered_flat\\Aabenraa.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from shapely.geometry import Point, Polygon\n",
    "from pathlib import Path\n",
    "\n",
    "# ── CONFIGURATION ──\n",
    "CHUNK_SIZE = 900_000\n",
    "IN_DIR     = Path(r\"D:\\Thesis Work MLS\\Denmark AIS data\\processed_files\")\n",
    "OUT_DIR    = IN_DIR / \"ports_filtered_flat\"\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# ── DEFINE YOUR PORT POLYGONS (lon, lat) ──\n",
    "port_polygons = {\n",
    "    \"Aarhaus\": Polygon([\n",
    "        (10.2177641, 56.1759993),\n",
    "        (10.2017995, 56.1264703),\n",
    "        (10.2697775, 56.143784),\n",
    "        (10.2610227, 56.1722725),\n",
    "        (10.2177641, 56.1759993),\n",
    "    ]),\n",
    "    \"Copenhagen\": Polygon([\n",
    "        (12.5763894, 55.73307),\n",
    "        (12.5889207, 55.6851003),\n",
    "        (12.6522637, 55.6895516),\n",
    "        (12.6393891, 55.736646),\n",
    "        (12.5763894, 55.73307),\n",
    "    ]),\n",
    "    \"Esbjerg\": Polygon([\n",
    "        (8.4107708, 55.4876855),\n",
    "        (8.3848499, 55.4803903),\n",
    "        (8.3996128, 55.4458413),\n",
    "        (8.446133,   55.4358116),\n",
    "        (8.4797786,  55.4554792),\n",
    "        (8.4107708,  55.4876855),\n",
    "    ]),\n",
    "    \"Fredericia\": Polygon([\n",
    "        (9.7232345, 55.5522225),\n",
    "        (9.7699264, 55.5505717),\n",
    "        (9.7761062, 55.5716379),\n",
    "        (9.7566227, 55.5717835),\n",
    "        (9.723492,  55.5525623),\n",
    "        (9.7232345, 55.5522225),\n",
    "    ]),\n",
    "    \"Aalborg\": Polygon([\n",
    "        (10.0493519, 57.070164),\n",
    "        (10.0181096, 57.0567239),\n",
    "        (10.069608,  57.0298291),\n",
    "        (10.1053135, 57.0477611),\n",
    "        (10.0493519, 57.070164),\n",
    "    ]),\n",
    "    \"Kalundborg\": Polygon([\n",
    "        (11.0498775, 55.6901745),\n",
    "        (11.0126249, 55.6667502),\n",
    "        (11.0850684, 55.65203),\n",
    "        (11.1192311, 55.6719783),\n",
    "        (11.0498775, 55.6901745),\n",
    "    ]),\n",
    "    \"Aabenraa\": Polygon([\n",
    "        (9.4196162, 55.0475791),\n",
    "        (9.421762,  55.0197381),\n",
    "        (9.4497428, 55.0209682),\n",
    "        (9.4421897, 55.0472349),\n",
    "        (9.4196162, 55.0475791),\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# ── PRECOMPUTE BOUNDING BOXES FOR FAST PREFILTER ──\n",
    "port_bounds = {name: poly.bounds for name, poly in port_polygons.items()}\n",
    "\n",
    "# ── SET UP OUTPUT WRITERS & SUMMARY COUNTERS ──\n",
    "writers = {}\n",
    "summary = {name: 0 for name in port_polygons}\n",
    "\n",
    "for port in port_polygons:\n",
    "    out_csv = OUT_DIR / f\"{port}.csv\"\n",
    "    writers[port] = {\"path\": out_csv, \"first\": True}\n",
    "\n",
    "# ── PROCESS EACH CSV IN CHUNKS ──\n",
    "print(f\"Starting spatial filter on {len(list(IN_DIR.glob('*.csv')))} files…\")\n",
    "for src in sorted(IN_DIR.glob(\"*.csv\")):\n",
    "    print(f\" ▶ Reading {src.name}\")\n",
    "    for chunk in pd.read_csv(\n",
    "        src,\n",
    "        chunksize=CHUNK_SIZE,\n",
    "        low_memory=False  # IMPORTANT: do NOT parse dates, just leave as strings\n",
    "    ):\n",
    "        # drop rows missing coords or Ship type\n",
    "        chunk = chunk.dropna(subset=[\"Latitude\", \"Longitude\", \"Ship type\"])\n",
    "\n",
    "        # Remove all rows where Ship type is 'Undefined' (case-insensitive, handles whitespace)\n",
    "        chunk = chunk[chunk[\"Ship type\"].str.strip().str.lower() != 'undefined']\n",
    "\n",
    "        # For each port: bounding-box then polygon test\n",
    "        for port, poly in port_polygons.items():\n",
    "            minx, miny, maxx, maxy = port_bounds[port]\n",
    "            bb_mask = (\n",
    "                (chunk[\"Longitude\"] >= minx) &\n",
    "                (chunk[\"Longitude\"] <= maxx) &\n",
    "                (chunk[\"Latitude\"]  >= miny) &\n",
    "                (chunk[\"Latitude\"]  <= maxy)\n",
    "            )\n",
    "            candidate = chunk[bb_mask]\n",
    "            if candidate.empty:\n",
    "                continue\n",
    "\n",
    "            # precise geometry containment\n",
    "            mask = candidate.apply(\n",
    "                lambda r: poly.contains(Point(r[\"Longitude\"], r[\"Latitude\"])),\n",
    "                axis=1\n",
    "            )\n",
    "            filtered = candidate[mask]\n",
    "            if filtered.empty:\n",
    "                continue\n",
    "\n",
    "            # write out ALL columns for rows inside this port\n",
    "            w = writers[port]\n",
    "            if w[\"first\"]:\n",
    "                filtered.to_csv(w[\"path\"], index=False, mode='w')\n",
    "                w[\"first\"] = False\n",
    "            else:\n",
    "                filtered.to_csv(w[\"path\"], index=False, header=False, mode='a')\n",
    "\n",
    "            summary[port] += len(filtered)\n",
    "\n",
    "    print(f\"   Done {src.name}\")\n",
    "\n",
    "# ── FINAL SUMMARY ──\n",
    "print(\"\\nRows retained per port:\")\n",
    "for port, cnt in summary.items():\n",
    "    print(f\" • {port}: {cnt:,} rows → {writers[port]['path']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407e475c-5a8c-476c-8386-fbc94ae49e31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
