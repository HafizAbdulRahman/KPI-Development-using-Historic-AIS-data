{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29c72c14-3f07-44d6-aee3-27fe630652a7",
   "metadata": {},
   "source": [
    "## Summaries files development\n",
    "Here you see we have 2nd polygon which exactly bounds the terminal locations for the selected ports. So, it allows to filter down turnaround times and comparsion with their length distribution. Here I considered that the vessel was berthe if a vessel comes within the provided polygon below and stays within that polygon for atleast 60 minutes then it means the vessel was actually berthed. Then, there is also the possibility that a vessel made multiple visit as we have 4 months AIS data for which I have considered as a vessel is making multiple visit if there is difference of more than 24 hours between two timestamps for a unique vessel based on timestamps available in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47e034c4-090b-4144-8ff2-de1423fe02ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3e5aa59-542c-4cdb-ad63-c91c910a92e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Bergen Terminal.csv for terminal summaries...\n",
      "  Bergen_SecondPolygon: 381 berth events/info saved to D:\\Thesis Work MLS\\Norway Data Filtered\\Port_Split_Result\\Cleaned\\Terminal_Summaries2\\Bergen_SecondPolygon_summary.csv\n",
      "\n",
      "Processing Drammen Port.csv for terminal summaries...\n",
      "  Drammen_2ndPolygon: 152 berth events/info saved to D:\\Thesis Work MLS\\Norway Data Filtered\\Port_Split_Result\\Cleaned\\Terminal_Summaries2\\Drammen_2ndPolygon_summary.csv\n",
      "\n",
      "Processing Kristiansand Terminal.csv for terminal summaries...\n",
      "  Kristiansand_2ndPolygon: 199 berth events/info saved to D:\\Thesis Work MLS\\Norway Data Filtered\\Port_Split_Result\\Cleaned\\Terminal_Summaries2\\Kristiansand_2ndPolygon_summary.csv\n",
      "\n",
      "Processing Oslo Port Area.csv for terminal summaries...\n",
      "  Oslo_2ndPolygon_Filipstad: 157 berth events/info saved to D:\\Thesis Work MLS\\Norway Data Filtered\\Port_Split_Result\\Cleaned\\Terminal_Summaries2\\Oslo_2ndPolygon_Filipstad_summary.csv\n",
      "  Oslo_2ndPolygon_Sjuroya: 349 berth events/info saved to D:\\Thesis Work MLS\\Norway Data Filtered\\Port_Split_Result\\Cleaned\\Terminal_Summaries2\\Oslo_2ndPolygon_Sjuroya_summary.csv\n",
      "\n",
      "Processing Stavanger Westport Terminal.csv for terminal summaries...\n",
      "  Stavanger_2ndPolygon: 433 berth events/info saved to D:\\Thesis Work MLS\\Norway Data Filtered\\Port_Split_Result\\Cleaned\\Terminal_Summaries2\\Stavanger_2ndPolygon_summary.csv\n",
      "\n",
      "All terminal summaries generated!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "# --- Paths ---\n",
    "cleaned_folder = r'D:\\Thesis Work MLS\\Norway Data Filtered\\Port_Split_Result\\Cleaned'\n",
    "summary_folder = os.path.join(cleaned_folder, \"Terminal_Summaries2\")\n",
    "os.makedirs(summary_folder, exist_ok=True)\n",
    "\n",
    "files = [f for f in os.listdir(cleaned_folder) if f.lower().endswith('.csv')]\n",
    "\n",
    "# --- Terminal polygons ---\n",
    "TERMINAL_POLYGONS = {\n",
    "    \"Bergen_SecondPolygon\": Polygon([\n",
    "        (5.3090064, 60.3901893), (5.305144, 60.3861391), (5.3155724, 60.3830215),\n",
    "        (5.317643, 60.3840554), (5.3189305, 60.3850946), (5.3141137, 60.387984),\n",
    "        (5.3090064, 60.3901893)]),\n",
    "    \"Stavanger_2ndPolygon\": Polygon([\n",
    "        (5.5832126, 58.9213942), (5.582998, 58.9181596), (5.5870321, 58.9179602),\n",
    "        (5.5879333, 58.9214607), (5.5832126, 58.9213942)]),\n",
    "    \"Kristiansand_2ndPolygon\": Polygon([\n",
    "        (7.9882631, 58.1412228), (7.9940996, 58.1396088), (7.9933915, 58.142933),\n",
    "        (7.9897759, 58.1426895), (7.9882631, 58.1412228)]),\n",
    "    \"Drammen_2ndPolygon\": Polygon([\n",
    "        (10.2376171, 59.7395407), (10.2351281, 59.73581), (10.2404066, 59.7355504),\n",
    "        (10.2401921, 59.7394758), (10.2376171, 59.7395407)]),\n",
    "    \"Oslo_2ndPolygon_Filipstad\": Polygon([\n",
    "        (10.7198972, 59.9088206), (10.7098765, 59.9057866), (10.7111854, 59.9042049),\n",
    "        (10.7217855, 59.9079599), (10.7198972, 59.9088206)]),\n",
    "    \"Oslo_2ndPolygon_Sjuroya\": Polygon([\n",
    "        (10.7448538, 59.8860217), (10.7451757, 59.8829641), (10.7670625, 59.8834271),\n",
    "        (10.765775, 59.8860217), (10.7625349, 59.8877442), (10.7448538, 59.8860217)])\n",
    "}\n",
    "\n",
    "def vessel_category(ship_type):\n",
    "    try:\n",
    "        code = int(float(ship_type))\n",
    "        if 70 <= code <= 79:\n",
    "            return 'Cargo'\n",
    "        elif 80 <= code <= 89:\n",
    "            return 'Tanker'\n",
    "        else:\n",
    "            return f\"Other_{code}\"\n",
    "    except:\n",
    "        return \"Other\"\n",
    "\n",
    "def vessel_visits_and_berths(df, terminal_poly):\n",
    "    df = df.sort_values(['mmsi', 'date_time_utc'])\n",
    "    result = []\n",
    "    # Store mmsi that got a berth event (for marking non-berthing vessels)\n",
    "    mmsi_berth_record = set()\n",
    "\n",
    "    for mmsi, group in df.groupby('mmsi'):\n",
    "        group = group.reset_index(drop=True)\n",
    "        group['date_time_utc'] = pd.to_datetime(group['date_time_utc'])\n",
    "        group['longitude'] = pd.to_numeric(group['longitude'], errors='coerce')\n",
    "        group['latitude'] = pd.to_numeric(group['latitude'], errors='coerce')\n",
    "        group['speed_over_ground'] = pd.to_numeric(group['speed_over_ground'], errors='coerce')\n",
    "        group['inside'] = group.apply(\n",
    "            lambda r: terminal_poly.contains(Point(r['longitude'], r['latitude'])), axis=1)\n",
    "        # Segment visits (>=24h break = new visit)\n",
    "        visit_ids = [0]\n",
    "        for i in range(1, len(group)):\n",
    "            gap = (group.loc[i, 'date_time_utc'] - group.loc[i-1, 'date_time_utc']).total_seconds()\n",
    "            visit_ids.append(visit_ids[-1]+1 if gap > 24*3600 else visit_ids[-1])\n",
    "        group['visit_id'] = visit_ids\n",
    "\n",
    "        # Vessel attributes\n",
    "        ship_type_val = group['ship_type'].iloc[0] if 'ship_type' in group else ''\n",
    "        ship_name = group['ship_name'].iloc[0] if 'ship_name' in group else ''\n",
    "        length = group['length'].iloc[0] if 'length' in group else ''\n",
    "\n",
    "        vessel_main_type = vessel_category(ship_type_val)\n",
    "\n",
    "        any_berth = False\n",
    "        for visit_num, visit_grp in group.groupby('visit_id'):\n",
    "            visit_grp = visit_grp.reset_index(drop=True)\n",
    "            in_berth = False\n",
    "            entry_time = None\n",
    "            entry_idx = None\n",
    "\n",
    "            for i, row in visit_grp.iterrows():\n",
    "                # Enter terminal and SOG < 0.5\n",
    "                if row['inside'] and not in_berth and row['speed_over_ground'] < 0.5:\n",
    "                    entry_idx = i\n",
    "                    entry_time = row['date_time_utc']\n",
    "                    in_berth = True\n",
    "                elif (not row['inside'] or row['speed_over_ground'] >= 0.5) and in_berth:\n",
    "                    exit_idx = i-1\n",
    "                    exit_time = visit_grp.loc[exit_idx, 'date_time_utc']\n",
    "                    # Only count if 1 hour+ and SOG < 0.5 throughout stay\n",
    "                    period = visit_grp.loc[entry_idx:exit_idx]\n",
    "                    duration = (exit_time - entry_time).total_seconds()/60\n",
    "                    if duration >= 60 and (period['speed_over_ground']<0.5).all():\n",
    "                        # Detect possible waiting time (outside polygon and SOG < 0.5, min 30min, and not moved)\n",
    "                        waiting_time = None\n",
    "                        wait_end = entry_idx-1\n",
    "                        stop_start = stop_end = None\n",
    "                        for j in range(wait_end, -1, -1):\n",
    "                            r = visit_grp.loc[j]\n",
    "                            if (not r['inside']) and (r['speed_over_ground'] < 0.5):\n",
    "                                if stop_end is None:\n",
    "                                    stop_end = j\n",
    "                                stop_start = j\n",
    "                            else:\n",
    "                                if stop_end is not None:\n",
    "                                    stop_duration = (visit_grp.loc[stop_end, 'date_time_utc'] - visit_grp.loc[stop_start, 'date_time_utc']).total_seconds()/60\n",
    "                                    if stop_duration >= 30:\n",
    "                                        lon1, lat1 = visit_grp.loc[stop_start, ['longitude','latitude']]\n",
    "                                        lon2, lat2 = visit_grp.loc[stop_end, ['longitude','latitude']]\n",
    "                                        moved = ((abs(lon2-lon1) > 0.0001) or (abs(lat2-lat1) > 0.0001))\n",
    "                                        if not moved:\n",
    "                                            waiting_time = stop_duration\n",
    "                                        break\n",
    "                                    stop_end = stop_start = None\n",
    "                        result.append({\n",
    "                            'mmsi': row['mmsi'],\n",
    "                            'length': length,\n",
    "                            'ship_name': ship_name,\n",
    "                            'ship_type': vessel_main_type,\n",
    "                            'berth_entry_time': entry_time,\n",
    "                            'berth_exit_time': exit_time,\n",
    "                            'turnaround_minutes': duration,\n",
    "                            'waiting_time_minutes': waiting_time,\n",
    "                            'visit_number': visit_num+1\n",
    "                        })\n",
    "                        any_berth = True\n",
    "                        mmsi_berth_record.add(mmsi)\n",
    "                    in_berth = False\n",
    "            # If vessel still inside at end\n",
    "            if in_berth:\n",
    "                exit_time = visit_grp.iloc[-1]['date_time_utc']\n",
    "                period = visit_grp.loc[entry_idx:]\n",
    "                duration = (exit_time - entry_time).total_seconds()/60\n",
    "                if duration >= 60 and (period['speed_over_ground']<0.5).all():\n",
    "                    result.append({\n",
    "                        'mmsi': row['mmsi'],\n",
    "                        'length': length,\n",
    "                        'ship_name': ship_name,\n",
    "                        'ship_type': vessel_main_type,\n",
    "                        'berth_entry_time': entry_time,\n",
    "                        'berth_exit_time': exit_time,\n",
    "                        'turnaround_minutes': duration,\n",
    "                        'waiting_time_minutes': None,\n",
    "                        'visit_number': visit_num+1\n",
    "                    })\n",
    "                    any_berth = True\n",
    "                    mmsi_berth_record.add(mmsi)\n",
    "        # If vessel never berthed, record basic info with 0\n",
    "        if not any_berth:\n",
    "            result.append({\n",
    "                'mmsi': group['mmsi'].iloc[0],\n",
    "                'length': length,\n",
    "                'ship_name': ship_name,\n",
    "                'ship_type': vessel_main_type,\n",
    "                'berth_entry_time': None,\n",
    "                'berth_exit_time': None,\n",
    "                'turnaround_minutes': 0,\n",
    "                'waiting_time_minutes': None,\n",
    "                'visit_number': 1\n",
    "            })\n",
    "    return result\n",
    "\n",
    "# ---- MAIN: Loop Over Each Cleaned File and Terminal ----\n",
    "for fname in files:\n",
    "    in_path = os.path.join(cleaned_folder, fname)\n",
    "    print(f\"\\nProcessing {fname} for terminal summaries...\")\n",
    "    df = pd.read_csv(in_path, dtype=str)\n",
    "    if df.empty:\n",
    "        print(f\"  {fname}: No records\")\n",
    "        continue\n",
    "    df = df.dropna(subset=['mmsi', 'longitude', 'latitude', 'date_time_utc', 'length', 'ship_type', 'ship_name'])\n",
    "    for term_name, poly in TERMINAL_POLYGONS.items():\n",
    "        if not term_name.split(\"_\")[0].lower() in fname.lower():\n",
    "            continue\n",
    "        result = vessel_visits_and_berths(df, poly)\n",
    "        if result:\n",
    "            result_df = pd.DataFrame(result)\n",
    "            out_path = os.path.join(summary_folder, f\"{term_name}_summary.csv\")\n",
    "            result_df.to_csv(out_path, index=False)\n",
    "            print(f\"  {term_name}: {len(result_df)} berth events/info saved to {out_path}\")\n",
    "        else:\n",
    "            print(f\"  {term_name}: No qualifying events found.\")\n",
    "\n",
    "print(\"\\nAll terminal summaries generated!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0487a0b-fdf8-466a-bd2f-abe4c21308c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
