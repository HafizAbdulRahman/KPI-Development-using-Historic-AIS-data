{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abf70b04-ce29-46c6-b7c0-cc3a9f239c51",
   "metadata": {},
   "source": [
    "## Squeeze the data based on Polygon\n",
    "Porvided the polgons, the code creates resultant files with ports names and each file from previous step is filtered such a way that any data points that falls within any of the provided polygon will be saved in respective port file in defined location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3bc0f65-353d-4233-8545-24dfe01e209a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 121 files...\n",
      "▶ hais_2024-01-01.csv\n",
      "▶ hais_2024-01-02.csv\n",
      "▶ hais_2024-01-03.csv\n",
      "▶ hais_2024-01-04.csv\n",
      "▶ hais_2024-01-05.csv\n",
      "▶ hais_2024-01-06.csv\n",
      "▶ hais_2024-01-07.csv\n",
      "▶ hais_2024-01-08.csv\n",
      "▶ hais_2024-01-09.csv\n",
      "▶ hais_2024-01-10.csv\n",
      "▶ hais_2024-01-11.csv\n",
      "▶ hais_2024-01-12.csv\n",
      "▶ hais_2024-01-13.csv\n",
      "▶ hais_2024-01-14.csv\n",
      "▶ hais_2024-01-15.csv\n",
      "▶ hais_2024-01-16.csv\n",
      "▶ hais_2024-01-17.csv\n",
      "▶ hais_2024-01-18.csv\n",
      "▶ hais_2024-01-19.csv\n",
      "▶ hais_2024-01-20.csv\n",
      "▶ hais_2024-01-21.csv\n",
      "▶ hais_2024-01-22.csv\n",
      "▶ hais_2024-01-23.csv\n",
      "▶ hais_2024-01-24.csv\n",
      "▶ hais_2024-01-25.csv\n",
      "▶ hais_2024-01-26.csv\n",
      "▶ hais_2024-01-27.csv\n",
      "▶ hais_2024-01-28.csv\n",
      "▶ hais_2024-01-29.csv\n",
      "▶ hais_2024-01-30.csv\n",
      "▶ hais_2024-01-31.csv\n",
      "▶ hais_2024-02-01.csv\n",
      "▶ hais_2024-02-02.csv\n",
      "▶ hais_2024-02-03.csv\n",
      "▶ hais_2024-02-04.csv\n",
      "▶ hais_2024-02-05.csv\n",
      "▶ hais_2024-02-06.csv\n",
      "▶ hais_2024-02-07.csv\n",
      "▶ hais_2024-02-08.csv\n",
      "▶ hais_2024-02-09.csv\n",
      "▶ hais_2024-02-10.csv\n",
      "▶ hais_2024-02-11.csv\n",
      "▶ hais_2024-02-12.csv\n",
      "▶ hais_2024-02-13.csv\n",
      "▶ hais_2024-02-14.csv\n",
      "▶ hais_2024-02-15.csv\n",
      "▶ hais_2024-02-16.csv\n",
      "▶ hais_2024-02-17.csv\n",
      "▶ hais_2024-02-18.csv\n",
      "▶ hais_2024-02-19.csv\n",
      "▶ hais_2024-02-20.csv\n",
      "▶ hais_2024-02-21.csv\n",
      "▶ hais_2024-02-22.csv\n",
      "▶ hais_2024-02-23.csv\n",
      "▶ hais_2024-02-24.csv\n",
      "▶ hais_2024-02-25.csv\n",
      "▶ hais_2024-02-26.csv\n",
      "▶ hais_2024-02-27.csv\n",
      "▶ hais_2024-02-28.csv\n",
      "▶ hais_2024-02-29.csv\n",
      "▶ hais_2024-03-01.csv\n",
      "▶ hais_2024-03-02.csv\n",
      "▶ hais_2024-03-03.csv\n",
      "▶ hais_2024-03-04.csv\n",
      "▶ hais_2024-03-05.csv\n",
      "▶ hais_2024-03-06.csv\n",
      "▶ hais_2024-03-07.csv\n",
      "▶ hais_2024-03-08.csv\n",
      "▶ hais_2024-03-09.csv\n",
      "▶ hais_2024-03-10.csv\n",
      "▶ hais_2024-03-11.csv\n",
      "▶ hais_2024-03-12.csv\n",
      "▶ hais_2024-03-13.csv\n",
      "▶ hais_2024-03-14.csv\n",
      "▶ hais_2024-03-15.csv\n",
      "▶ hais_2024-03-16.csv\n",
      "▶ hais_2024-03-17.csv\n",
      "▶ hais_2024-03-18.csv\n",
      "▶ hais_2024-03-19.csv\n",
      "▶ hais_2024-03-20.csv\n",
      "▶ hais_2024-03-21.csv\n",
      "▶ hais_2024-03-22.csv\n",
      "▶ hais_2024-03-23.csv\n",
      "▶ hais_2024-03-24.csv\n",
      "▶ hais_2024-03-25.csv\n",
      "▶ hais_2024-03-26.csv\n",
      "▶ hais_2024-03-27.csv\n",
      "▶ hais_2024-03-28.csv\n",
      "▶ hais_2024-03-29.csv\n",
      "▶ hais_2024-03-30.csv\n",
      "▶ hais_2024-03-31.csv\n",
      "▶ hais_2024-04-01.csv\n",
      "▶ hais_2024-04-02.csv\n",
      "▶ hais_2024-04-03.csv\n",
      "▶ hais_2024-04-04.csv\n",
      "▶ hais_2024-04-05.csv\n",
      "▶ hais_2024-04-06.csv\n",
      "▶ hais_2024-04-07.csv\n",
      "▶ hais_2024-04-08.csv\n",
      "▶ hais_2024-04-09.csv\n",
      "▶ hais_2024-04-10.csv\n",
      "▶ hais_2024-04-11.csv\n",
      "▶ hais_2024-04-12.csv\n",
      "▶ hais_2024-04-13.csv\n",
      "▶ hais_2024-04-14.csv\n",
      "▶ hais_2024-04-15.csv\n",
      "▶ hais_2024-04-16.csv\n",
      "▶ hais_2024-04-17.csv\n",
      "▶ hais_2024-04-18.csv\n",
      "▶ hais_2024-04-19.csv\n",
      "▶ hais_2024-04-20.csv\n",
      "▶ hais_2024-04-21.csv\n",
      "▶ hais_2024-04-22.csv\n",
      "▶ hais_2024-04-23.csv\n",
      "▶ hais_2024-04-24.csv\n",
      "▶ hais_2024-04-25.csv\n",
      "▶ hais_2024-04-26.csv\n",
      "▶ hais_2024-04-27.csv\n",
      "▶ hais_2024-04-28.csv\n",
      "▶ hais_2024-04-29.csv\n",
      "▶ hais_2024-04-30.csv\n",
      "\n",
      "Rows retained per port:\n",
      " • Bergen Terminal: 3,333,696 rows → D:\\Thesis Work MLS\\Norway Data Filtered\\Port_Split_Result\\Bergen Terminal.csv\n",
      " • Stavanger Westport Terminal: 1,303,513 rows → D:\\Thesis Work MLS\\Norway Data Filtered\\Port_Split_Result\\Stavanger Westport Terminal.csv\n",
      " • Kristiansand Terminal: 376,905 rows → D:\\Thesis Work MLS\\Norway Data Filtered\\Port_Split_Result\\Kristiansand Terminal.csv\n",
      " • Drammen Port: 308,285 rows → D:\\Thesis Work MLS\\Norway Data Filtered\\Port_Split_Result\\Drammen Port.csv\n",
      " • Oslo Port Area: 1,210,792 rows → D:\\Thesis Work MLS\\Norway Data Filtered\\Port_Split_Result\\Oslo Port Area.csv\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "CHUNK_SIZE = 1000_000\n",
    "input_folder = r'D:\\Thesis Work MLS\\Norway Data Filtered'\n",
    "output_folder = os.path.join(input_folder, \"Port_Split_Result\")\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "PORT_POLYGONS = {\n",
    "    \"Bergen Terminal\": Polygon([(5.3119966, 60.4048807), (5.2689096, 60.3941969), (5.3233262, 60.3710367), (5.3526803, 60.3832551), (5.3119966, 60.4048807)]),\n",
    "    \"Stavanger Westport Terminal\": Polygon([(5.5596949, 58.9367236), (5.5461337, 58.9152819), (5.5955721, 58.9039355), (5.6122233, 58.9324718), (5.5596949, 58.9367236)]),\n",
    "    \"Kristiansand Terminal\": Polygon([(8.0021276, 58.157283), (7.9581823, 58.1337279), (8.0220403, 58.1192246), (8.0388631, 58.1449638), (8.0021276, 58.157283)]),\n",
    "    \"Drammen Port\": Polygon([(10.2470522, 59.7538991), (10.1914339, 59.7347841), (10.2879076, 59.7134939), (10.3028421, 59.7476728), (10.2470522, 59.7538991)]),\n",
    "    \"Oslo Port Area\": Polygon([(10.7220254, 59.9127971), (10.6775651, 59.9016079), (10.7091508, 59.8693961), (10.7781586, 59.8841278), (10.7587609, 59.9135716), (10.7220254, 59.9127971)])\n",
    "}\n",
    "\n",
    "port_bounds = {port: poly.bounds for port, poly in PORT_POLYGONS.items()}\n",
    "port_paths = {port: os.path.join(output_folder, f\"{port}.csv\") for port in PORT_POLYGONS}\n",
    "header_written = {port: False for port in PORT_POLYGONS}\n",
    "summary = {port: 0 for port in PORT_POLYGONS}\n",
    "\n",
    "input_files = [f for f in os.listdir(input_folder) if f.lower().endswith('.csv')]\n",
    "\n",
    "print(f\"Processing {len(input_files)} files...\")\n",
    "\n",
    "for fname in input_files:\n",
    "    file_path = os.path.join(input_folder, fname)\n",
    "    print(f\"▶ {fname}\")\n",
    "    try:\n",
    "        chunk_iter = pd.read_csv(\n",
    "            file_path,\n",
    "            chunksize=CHUNK_SIZE,\n",
    "            dtype=str,\n",
    "            engine='python',\n",
    "            escapechar='\\\\'\n",
    "        )\n",
    "        for chunk in chunk_iter:\n",
    "            # Drop NA in lat/lon and filter out header lines (column name as value)\n",
    "            chunk = chunk.dropna(subset=['latitude', 'longitude']).copy()\n",
    "            chunk = chunk[~chunk['longitude'].str.lower().eq('longitude')]\n",
    "            chunk = chunk[~chunk['latitude'].str.lower().eq('latitude')]\n",
    "            # Convert to float (non-numeric will become NaN and dropped)\n",
    "            chunk['longitude'] = pd.to_numeric(chunk['longitude'], errors='coerce')\n",
    "            chunk['latitude'] = pd.to_numeric(chunk['latitude'], errors='coerce')\n",
    "            chunk = chunk.dropna(subset=['longitude', 'latitude'])\n",
    "\n",
    "            for port, poly in PORT_POLYGONS.items():\n",
    "                minx, miny, maxx, maxy = port_bounds[port]\n",
    "                bb_mask = (\n",
    "                    (chunk['longitude'] >= minx) & (chunk['longitude'] <= maxx) &\n",
    "                    (chunk['latitude']  >= miny) & (chunk['latitude']  <= maxy)\n",
    "                )\n",
    "                candidate = chunk[bb_mask]\n",
    "                if candidate.empty:\n",
    "                    continue\n",
    "                mask = candidate.apply(lambda r: poly.contains(Point(r['longitude'], r['latitude'])), axis=1)\n",
    "                filtered = candidate[mask]\n",
    "                if not filtered.empty:\n",
    "                    filtered.to_csv(\n",
    "                        port_paths[port],\n",
    "                        mode='a',\n",
    "                        index=False,\n",
    "                        header=not header_written[port]\n",
    "                    )\n",
    "                    header_written[port] = True\n",
    "                    summary[port] += len(filtered)\n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ Error in file {fname}: {e}\")\n",
    "\n",
    "print(\"\\nRows retained per port:\")\n",
    "for port, cnt in summary.items():\n",
    "    print(f\" • {port}: {cnt:,} rows → {port_paths[port]}\")\n",
    "print(\"\\nDone!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaa96a7-d0c4-43fc-b26e-6d37a1a087ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
